{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matt14e/StitchAI/blob/main/Stitchmodel3_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qLNwskXOkXEr"
      },
      "outputs": [],
      "source": [
        "!pip -q install lightning torchvision pyembroidery pillow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tyrao3aZkljC",
        "outputId": "a96fdd1a-9676-483f-e7b3-2b6b15ae5b11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚îÄ‚îÄ ONE-SHOT PATCH: make GitHub happy ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "# Prerequisite: you have already run   drive.mount(\"/content/drive\")\n",
        "\n",
        "!pip -q install nbformat\n",
        "import nbformat, pathlib\n",
        "\n",
        "# exact path to the notebook you‚Äôre working on (include /content/drive/‚Ä¶)\n",
        "nb_path = pathlib.Path(\n",
        "    \"/content/drive/MyDrive/Colab Notebooks/Stitchmodel3 (1).ipynb\"\n",
        ")\n",
        "\n",
        "# read ‚Üí ensure widgets.state exists ‚Üí write back\n",
        "nb = nbformat.read(nb_path, as_version=nbformat.NO_CONVERT)\n",
        "nb.metadata.setdefault(\"widgets\", {}).setdefault(\"state\", {})   # the missing key\n",
        "nbformat.write(nb, nb_path)\n",
        "\n",
        "print(f\"‚úÖ Patched: {nb_path.name} ‚Äî now hit  File ‚ñ∏ Save a copy in GitHub\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdPUS4tEAZZs",
        "outputId": "51b557ab-7c14-429f-9f3c-2db76923ea99"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Patched: Stitchmodel3 (1).ipynb ‚Äî now hit  File ‚ñ∏ Save a copy in GitHub\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚îÄ‚îÄ FINAL ONE-SHOT FIX FOR GITHUB RENDERING ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "# 1) Mount Drive (skip if already mounted)\n",
        "from google.colab import drive, runtime\n",
        "try:\n",
        "    drive.mount(\"/content/drive\")\n",
        "except RuntimeError:\n",
        "    pass  # already mounted\n",
        "\n",
        "# 2) Install nbformat\n",
        "!pip -q install nbformat\n",
        "import nbformat, pathlib\n",
        "\n",
        "nb_path = pathlib.Path(\n",
        "    \"/content/drive/MyDrive/Colab Notebooks/Stitchmodel3 (1).ipynb\"\n",
        ")\n",
        "\n",
        "# 3) Load notebook\n",
        "nb = nbformat.read(nb_path, as_version=nbformat.NO_CONVERT)\n",
        "\n",
        "# 4) Ensure the required key exists\n",
        "outer = nb.metadata.setdefault(\"widgets\", {})\n",
        "blob_key = \"application/vnd.jupyter.widget-state+json\"\n",
        "inner = outer.setdefault(blob_key, {})\n",
        "inner.setdefault(\"state\", {})           # the piece GitHub insists on\n",
        "inner.setdefault(\"version_major\", 2)\n",
        "inner.setdefault(\"version_minor\", 0)\n",
        "\n",
        "# 5) Write back\n",
        "nbformat.write(nb, nb_path)\n",
        "\n",
        "print(f\"‚úÖ Patched {nb_path.name} ‚Äî now choose  File ‚ñ∏ Save a copy in GitHub\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2EUVIV3A397",
        "outputId": "d1115c51-275d-4bd0-ac44-701420aa1709"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "‚úÖ Patched Stitchmodel3 (1).ipynb ‚Äî now choose  File ‚ñ∏ Save a copy in GitHub\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob, pathlib, textwrap, os\n",
        "\n",
        "# List every .ipynb file reachable from the current directory\n",
        "candidates = glob.glob(\"**/*.ipynb\", recursive=True)\n",
        "\n",
        "print(textwrap.dedent(f\"\"\"\n",
        "    üîç Found {len(candidates)} notebook(s):\n",
        "    ----------------------------------------\n",
        "    {os.linesep.join(candidates) or '(none)'}\n",
        "\"\"\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-cZzvDeVbAz",
        "outputId": "3f7af824-e239-4b78-f239-23b0fd468891"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    üîç Found 70 notebook(s):\n",
            "    ----------------------------------------\n",
            "    drive/MyDrive/Economics/Behavioral Economics/Behavioral project/pset3coding.ipynb\n",
            "drive/MyDrive/Economics/Machine Learning BYU/Khalel.ipynb\n",
            "drive/MyDrive/Economics/Machine Learning BYU/Colab Notebooks/helloworld.ipynb\n",
            "drive/MyDrive/Economics/Machine Learning BYU/Colab Notebooks/python_intro.ipynb\n",
            "drive/MyDrive/Economics/Machine Learning BYU/Colab Notebooks/Copy of 01-pset1coding_BF (1).ipynb\n",
            "drive/MyDrive/Economics/Machine Learning BYU/Colab Notebooks/Copy of 01-pset1coding_BF.ipynb\n",
            "drive/MyDrive/Economics/Machine Learning BYU/Colab Notebooks/Copy of pset3coding (1).ipynb\n",
            "drive/MyDrive/Economics/Machine Learning BYU/Colab Notebooks/Copy of pset3coding.ipynb\n",
            "drive/MyDrive/Economics/Machine Learning BYU/Colab Notebooks/Copy of pset3mattelmer.ipynb\n",
            "drive/MyDrive/Economics/Machine Learning BYU/Colab Notebooks/Copy of MattElmer'smidterm2023winter.ipynb\n",
            "drive/MyDrive/Economics/Machine Learning BYU/Colab Notebooks/Copy22 of MattElmer'smidterm2023winter.ipynb\n",
            "drive/MyDrive/Economics/Machine Learning BYU/Colab Notebooks/MattElmerpset5coding.ipynb\n",
            "drive/MyDrive/Economics/Machine Learning BYU/Colab Notebooks/Copy of Copy of MattElmerpset5coding.ipynb\n",
            "drive/MyDrive/Economics/Machine Learning BYU/Colab Notebooks/Copy of MattElmerpset5coding.ipynb\n",
            "drive/MyDrive/Economics/Machine Learning BYU/Colab Notebooks/MattKaggle.ipynb\n",
            "drive/MyDrive/Economics/Machine Learning BYU/Colab Notebooks/MattKaggle2.ipynb\n",
            "drive/MyDrive/Economics/Machine Learning BYU/Colab Notebooks/MattElmerKaggle.ipynb\n",
            "drive/MyDrive/Economics/Machine Learning BYU/Colab Notebooks/MattElmer'smidterm2023winter.ipynb\n",
            "drive/MyDrive/Economics/Machine Learning BYU/Colab Notebooks/Copy of Season&HolidayVariables.ipynb\n",
            "drive/MyDrive/Economics/Machine Learning BYU/Colab Notebooks/Untitled0.ipynb\n",
            "drive/MyDrive/Economics/Machine Learning BYU/Colab Notebooks/MatthewElmerfinal2023winter.ipynb\n",
            "drive/MyDrive/Economics/Machine Learning BYU/Colab Notebooks/twitterbottesting.ipynb\n",
            "drive/MyDrive/Economics/Machine Learning BYU/Colab Notebooks/sunroof1.ipynb\n",
            "drive/MyDrive/Economics/Machine Learning BYU/Colab Notebooks/sunroof2.ipynb\n",
            "drive/MyDrive/Economics/Machine Learning BYU/Colab Notebooks/Untitled1.ipynb\n",
            "drive/MyDrive/Economics/Machine Learning BYU/Colab Notebooks/Untitled2.ipynb\n",
            "drive/MyDrive/Economics/Machine Learning BYU/Colab Notebooks/pset5coding.ipynb\n",
            "drive/MyDrive/Economics/Machine Learning BYU/Econ 484/Causal Regression + ML.ipynb\n",
            "drive/MyDrive/Economics/Machine Learning BYU/Econ 484/class examples/supervisedintro.ipynb\n",
            "drive/MyDrive/Economics/Machine Learning BYU/Econ 484/class examples/wordledemo.ipynb\n",
            "drive/MyDrive/Economics/Machine Learning BYU/Econ 484/class examples/controls.ipynb\n",
            "drive/MyDrive/Economics/Machine Learning BYU/Econ 484/class examples/trees.ipynb\n",
            "drive/MyDrive/Economics/Machine Learning BYU/Econ 484/class examples/tweet demo.ipynb\n",
            "drive/MyDrive/Economics/Machine Learning BYU/Econ 484/class examples/01-python-introduction.ipynb\n",
            "drive/MyDrive/Economics/Machine Learning BYU/Econ 484/class examples/Hello World.ipynb\n",
            "drive/MyDrive/Economics/Machine Learning BYU/Econ 484/class examples/Causal via Prediction.ipynb\n",
            "drive/MyDrive/Economics/Machine Learning BYU/Econ 484/class examples/penalizedregression.ipynb\n",
            "drive/MyDrive/Economics/Machine Learning BYU/Econ 484/class examples/00-jupyter-notebook_intro.ipynb\n",
            "drive/MyDrive/Economics/Machine Learning BYU/Econ 484/class examples/Basic regression1.ipynb\n",
            "drive/MyDrive/Economics/Machine Learning BYU/Econ 484/class examples/clustering.ipynb\n",
            "drive/MyDrive/Economics/Machine Learning BYU/Econ 484/class examples/pca.ipynb\n",
            "drive/MyDrive/Economics/Machine Learning BYU/Econ 484/class examples/randomforest.ipynb\n",
            "drive/MyDrive/Economics/Machine Learning BYU/Econ 484/class examples/ROC example.ipynb\n",
            "drive/MyDrive/Economics/Machine Learning BYU/Econ 484/class examples/svm.ipynb\n",
            "drive/MyDrive/Economics/Machine Learning BYU/Econ 484/class examples/neural network.ipynb\n",
            "drive/MyDrive/Economics/Machine Learning BYU/Econ 484/class examples/movies.ipynb\n",
            "drive/MyDrive/Economics/Machine Learning BYU/Econ 484/class examples/heterogeneous treatment effects.ipynb\n",
            "drive/MyDrive/Economics/Machine Learning BYU/Econ 484/class examples/movies IV.ipynb\n",
            "drive/MyDrive/Economics/Machine Learning BYU/Econ 484/psets/01-pset1coding_BF.ipynb\n",
            "drive/MyDrive/Economics/Machine Learning BYU/Econ 484/psets/01-pset1coding_LN_KEY.ipynb\n",
            "drive/MyDrive/Economics/Machine Learning BYU/Econ 484/Untitled folder/python_intro.ipynb\n",
            "drive/MyDrive/Economics/Machine Learning BYU/Econ 484 Project/Season&HolidayVariables.ipynb\n",
            "drive/MyDrive/Economics/Machine Learning BYU/Econ 484 Project/ZIPS.ipynb\n",
            "drive/MyDrive/Economics/Machine Learning BYU/Econ 484 Project/newobs_weekly.ipynb\n",
            "drive/MyDrive/Economics/Machine Learning BYU/Econ 484 Project/Copy of Copy of Foot_Traffic_Model.ipynb\n",
            "drive/MyDrive/Economics/Machine Learning BYU/Econ 484 Project/Data_Merging.ipynb\n",
            "drive/MyDrive/Economics/Machine Learning BYU/Econ 484 Project/REAL Copy of Foot_Traffic_Model.ipynb\n",
            "drive/MyDrive/Economics/Machine Learning BYU/Econ 484 Project/Foot_Traffic_Model.ipynb\n",
            "drive/MyDrive/Economics/Machine Learning BYU/Econ 484 Project/Unlabeled_cleaning.ipynb\n",
            "drive/MyDrive/Economics/Machine Learning BYU/Econ 484 Project/CA Weather Data/Weather.ipynb\n",
            "drive/MyDrive/Economics/Machine Learning BYU/Econ 484 Project/CA Weather Data_Dickson/Weather_Data.ipynb\n",
            "drive/MyDrive/Economics/Machine Learning BYU/Econ 484 Project/To be turned in/Foot_Traffic_Model_2.ipynb\n",
            "drive/MyDrive/StitchAI/Stitchmodelpractice1.ipynb\n",
            "drive/MyDrive/Colab Notebooks/NumberPredictorModel.ipynb\n",
            "drive/MyDrive/Colab Notebooks/Stitchmodel2.ipynb\n",
            "drive/MyDrive/Colab Notebooks/pre_processing.ipynb\n",
            "drive/MyDrive/Colab Notebooks/Untitled0.ipynb\n",
            "drive/MyDrive/Colab Notebooks/Stitchmodel3bad.ipynb\n",
            "drive/MyDrive/Colab Notebooks/DSTdecoder.ipynb\n",
            "drive/MyDrive/Colab Notebooks/Stitchmodel3 (1).ipynb\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚ñ∂Ô∏é 2.  Install nbformat (small dependency)\n",
        "!pip -q install nbformat\n",
        "import nbformat\n",
        "\n",
        "# ‚ñ∂Ô∏é 3.  ABSOLUTE path to your notebook  ‚Üê‚îÄ‚îÄ copy-paste exactly as shown\n",
        "nb_path = \"drive/MyDrive/Colab Notebooks/Stitchmodel3 (1).ipynb\"\n",
        "\n",
        "# ‚ñ∂Ô∏é 4.  Load ‚Üí strip bad widgets ‚Üí save\n",
        "with open(nb_path, encoding=\"utf-8\") as f:\n",
        "    nb = nbformat.read(f, as_version=nbformat.NO_CONVERT)\n",
        "\n",
        "removed = nb.metadata.pop(\"widgets\", None)   # drop entire widgets block\n",
        "\n",
        "with open(nb_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    nbformat.write(nb, f)\n",
        "\n",
        "print(\n",
        "    f\"‚úÖ Cleaned '{nb_path}'. \"\n",
        "    + (\"widgets metadata removed.\" if removed else \"No widgets metadata found.\")\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mApV2yChVI_s",
        "outputId": "440c06ca-da09-4786-fbdc-7de809e0f8f1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Cleaned 'drive/MyDrive/Colab Notebooks/Stitchmodel3 (1).ipynb'. No widgets metadata found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#patch cell\n",
        "# üõ†  Make GitHub happy: ensure metadata.widgets.state exists\n",
        "import nbformat, os, io, json, IPython\n",
        "\n",
        "nb_path = os.environ[\"COLAB_NOTEBOOK_NAME\"]      # always the open notebook\n",
        "print(\"‚Ü™Ô∏é Patching\", nb_path)\n",
        "\n",
        "# -- read current in-memory file -------------\n",
        "with open(nb_path, encoding=\"utf-8\") as f:\n",
        "    nb = nbformat.read(f, as_version=nbformat.NO_CONVERT)\n",
        "\n",
        "# -- guarantee valid widgets structure -------\n",
        "widgets = nb.metadata.setdefault(\"widgets\", {})\n",
        "widgets.setdefault(\"state\", {})                 # <- the missing bit!\n",
        "\n",
        "# -- write back in place ----------------------\n",
        "with open(nb_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    nbformat.write(nb, f)\n",
        "\n",
        "print(\"‚úÖ Added empty widgets.state ‚Äî now click File ‚ñ∏ Save a copy in GitHub\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "id": "k-jPpQMp6Zes",
        "outputId": "4de4f967-1a8d-42ea-ef13-9b00dff42f53"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'COLAB_NOTEBOOK_NAME'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-d210ff253315>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnbformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mnb_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"COLAB_NOTEBOOK_NAME\"\u001b[0m\u001b[0;34m]\u001b[0m      \u001b[0;31m# always the open notebook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"‚Ü™Ô∏é Patching\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/os.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'COLAB_NOTEBOOK_NAME'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# üõ† Make GitHub happy: be sure metadata.widgets.state exists\n",
        "import nbformat, os, glob, pathlib, textwrap\n",
        "\n",
        "# 1) Try env-var first, else auto-detect in cwd, else manual fallback\n",
        "nb_path = os.environ.get(\"COLAB_NOTEBOOK_NAME\")\n",
        "if not nb_path:\n",
        "    matches = glob.glob(\"*.ipynb\")\n",
        "    if len(matches) == 1:\n",
        "        nb_path = matches[0]                            # unique match\n",
        "    else:\n",
        "        raise FileNotFoundError(textwrap.dedent(f\"\"\"\n",
        "            Couldn't auto-detect the notebook file.\n",
        "            Please set nb_path manually, e.g.:\n",
        "                nb_path = \"drive/MyDrive/Colab Notebooks/Stitchmodel3 (1).ipynb\"\n",
        "        \"\"\"))\n",
        "\n",
        "print(\"‚Ü™Ô∏é Patching ‚Üí\", nb_path)\n",
        "\n",
        "# 2) Load, patch, save\n",
        "with open(nb_path, encoding=\"utf-8\") as f:\n",
        "    nb = nbformat.read(f, as_version=nbformat.NO_CONVERT)\n",
        "\n",
        "widgets = nb.metadata.setdefault(\"widgets\", {})\n",
        "widgets.setdefault(\"state\", {})               #  <-- the key GitHub needs\n",
        "\n",
        "with open(nb_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    nbformat.write(nb, f)\n",
        "\n",
        "print(\"‚úÖ Added empty widgets.state ‚Äî now click File ‚ñ∏ Save a copy in GitHub\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "3uUlhRYd--Tt",
        "outputId": "7529986c-48d0-4e36-bfb7-5eaccdd468d5"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "\nCouldn't auto-detect the notebook file.\nPlease set nb_path manually, e.g.:\n    nb_path = \"drive/MyDrive/Colab Notebooks/Stitchmodel3 (1).ipynb\"\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-eaa492f69575>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mnb_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m                            \u001b[0;31m# unique match\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         raise FileNotFoundError(textwrap.dedent(f\"\"\"\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0mCouldn\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0mt\u001b[0m \u001b[0mauto\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdetect\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mnotebook\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mPlease\u001b[0m \u001b[0mset\u001b[0m \u001b[0mnb_path\u001b[0m \u001b[0mmanually\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: \nCouldn't auto-detect the notebook file.\nPlease set nb_path manually, e.g.:\n    nb_path = \"drive/MyDrive/Colab Notebooks/Stitchmodel3 (1).ipynb\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "OT7pe-U1kngl"
      },
      "outputs": [],
      "source": [
        "# Edit here if folders are moved\n",
        "DATA_ROOT = \"/content/drive/MyDrive/Embroidery Files\"\n",
        "IMG_DIR   = f\"{DATA_ROOT}/PNG_image_files\"   # PNGs\n",
        "DST_DIR   = f\"{DATA_ROOT}/DST_digitized_files\"   # DSTs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hN6wh5IktHu",
        "outputId": "e7f86b0a-32b7-4798-85ef-86a6a3952392"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì∑  sample PNG files:\n",
            "    Cod_Fish_Logo.PNG\n",
            "    MLPP_LOGO.PNG\n",
            "    LF_LOGO.PNG\n",
            "    Andrews_Logo.PNG\n",
            "    Royal_Logo.PNG\n",
            "\n",
            "üßµ  sample DST files:\n",
            "    Elite.DST\n",
            "    Lehigh.DST\n",
            "    Moon-Walkaz-Text.DST\n",
            "    Kamp.DST\n",
            "    Nike.DST\n"
          ]
        }
      ],
      "source": [
        "#sanity check the folders\n",
        "import pathlib, textwrap\n",
        "\n",
        "print(\"üì∑  sample PNG files:\")\n",
        "for p in list(pathlib.Path(IMG_DIR).glob(\"*.[pP][nN][gG]\"))[:5]:\n",
        "    print(\"   \", p.name)\n",
        "\n",
        "print(\"\\nüßµ  sample DST files:\")\n",
        "for p in list(pathlib.Path(DST_DIR).glob(\"*.[dD][sS][tT]\"))[:5]:\n",
        "    print(\"   \", p.name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhjS9OvTfT9K",
        "outputId": "036624fb-d3ff-49f6-8c4d-f068cca3d979"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing dataset.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile dataset.py\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from pyembroidery import read\n",
        "\n",
        "# --- file patterns -----------------------------------------------------------\n",
        "IMG_EXTS = (\"*.png\", \"*.PNG\", \"*.jpg\", \"*.JPG\")\n",
        "DST_EXTS = (\"*.dst\", \"*.DST\")\n",
        "\n",
        "class EmbroDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Yields (image_tensor, stitch_tensor) pairs.\n",
        "\n",
        "    image_tensor  : C √ó H √ó W   float32 in [0, 1]\n",
        "    stitch_tensor : L √ó 3       (Œîx, Œîy, flag)  float32\n",
        "    \"\"\"\n",
        "    def __init__(self, img_dir, dst_dir, transform=None, max_len=4096):\n",
        "        img_dir, dst_dir = Path(img_dir), Path(dst_dir)\n",
        "\n",
        "        # -------- gather every image and dst file into dicts ---------------\n",
        "        img_files = {}\n",
        "        for pat in IMG_EXTS:\n",
        "            for p in img_dir.glob(pat):\n",
        "                img_files[p.stem] = p\n",
        "\n",
        "        dst_files = {}\n",
        "        for pat in DST_EXTS:\n",
        "            for d in dst_dir.glob(pat):\n",
        "                dst_files[d.stem] = d\n",
        "\n",
        "        # -------- keep only names that exist in *both* dicts --------------\n",
        "        self.common_names = sorted(img_files.keys() & dst_files.keys())\n",
        "        if not self.common_names:\n",
        "            raise RuntimeError(\"No matching (image, DST) pairs found!\")\n",
        "\n",
        "        self.img_files  = img_files\n",
        "        self.dst_files  = dst_files\n",
        "        self.transform  = transform\n",
        "        self.max_len    = max_len\n",
        "\n",
        "    # ------------------------------------------------------------------------\n",
        "    def __len__(self):\n",
        "        return len(self.common_names)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        name = self.common_names[idx]\n",
        "\n",
        "        # load & optionally transform image\n",
        "        img_path = self.img_files[name]\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        # load DST stitches\n",
        "        dst_path  = self.dst_files[name]\n",
        "        pattern   = read(str(dst_path))\n",
        "        stitches  = torch.tensor(pattern.stitches,\n",
        "                                 dtype=torch.float32)[: self.max_len]\n",
        "\n",
        "        return img, stitches\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kyfHUvedlvK_"
      },
      "outputs": [],
      "source": [
        "#dont run\n",
        "\n",
        "%%writefile dataset.py\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from pyembroidery import read\n",
        "\n",
        "IMG_EXTS = (\"*.png\", \"*.PNG\", \"*.jpg\", \"*.JPG\")\n",
        "DST_EXTS = (\"*.dst\", \"*.DST\")\n",
        "\n",
        "class EmbroDataset(Dataset):\n",
        "    \"\"\"\n",
        "    (image_tensor, stitch_tensor) pairs\n",
        "    image_tensor  : C√óH√óW  float32 [0,1]\n",
        "    stitch_tensor : L√ó3    (Œîx, Œîy, flag)\n",
        "    \"\"\"\n",
        "    def __init__(self, img_dir, dst_dir, transform=None, max_len=4096):\n",
        "        self.img_paths = []\n",
        "        for pat in IMG_EXTS:\n",
        "            self.img_paths.extend(Path(img_dir).glob(pat))\n",
        "        self.img_paths = sorted(self.img_paths)\n",
        "\n",
        "        self.dst_dir   = Path(dst_dir)\n",
        "        self.transform = transform\n",
        "        self.max_len   = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.img_paths[idx]\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        stem = img_path.stem\n",
        "        for ext in DST_EXTS:\n",
        "            cand = self.dst_dir / f\"{stem}{ext[1:]}\"   # '*.dst' ‚ûú '.dst'\n",
        "            if cand.exists():\n",
        "                dst_path = cand\n",
        "                break\n",
        "        else:\n",
        "            raise FileNotFoundError(f\"No DST match for {stem}\")\n",
        "\n",
        "        pattern  = read(str(dst_path))\n",
        "        stitches = torch.tensor(pattern.stitches,\n",
        "                                dtype=torch.float32)[: self.max_len]\n",
        "        return img, stitches\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FAooU3LhlxUf",
        "outputId": "3ef3e346-5193-4103-9ad6-9941228a0fa6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing model.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile model.py\n",
        "import torch, torch.nn as nn\n",
        "\n",
        "class EmbroNet(nn.Module):\n",
        "    \"\"\"Tiny CNN encoder + GRU decoder baseline.\"\"\"\n",
        "    def __init__(self, hidden=256):\n",
        "        super().__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, 3, 2, 1), nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, 3, 2, 1), nn.ReLU(),\n",
        "            nn.Conv2d(64,128, 3, 2, 1), nn.ReLU(),\n",
        "            nn.AdaptiveAvgPool2d(1)          # 128√ó1√ó1\n",
        "        )\n",
        "        self.enc_fc  = nn.Linear(128, hidden)\n",
        "\n",
        "        self.gru     = nn.GRU(3, hidden, num_layers=2, batch_first=True)\n",
        "        self.dec_fc  = nn.Linear(hidden, 3)\n",
        "\n",
        "    def forward(self, img, prev_cmds):\n",
        "        B = img.size(0)\n",
        "        h0 = self.encoder(img).view(B, -1)      # B√ó128\n",
        "        h0 = torch.tanh(self.enc_fc(h0)).unsqueeze(0).repeat(2, 1, 1)\n",
        "        out, _ = self.gru(prev_cmds, h0)        # B√óL√óH\n",
        "        return self.dec_fc(out)                 # B√óL√ó3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 730,
          "referenced_widgets": [
            "230177b74344490b8de7774a9bfc6aae",
            "fac27bea99c44f7cad19c2c15a16c82f",
            "b9b93abe1b6d4c739f9886f6bcbb19d6",
            "91162a4d61b6446c85cb1721f2e665dc",
            "b9c7663ae33e412dba808faa9242fa46",
            "58bdc58cf04545888d6d86ed03544b91",
            "353f24df063c41b3ac06e0c270788933",
            "82355f83fbba453e8da018a7703ef0c2",
            "c4e8fde829b44ad1b3b78ad6291af1c9",
            "38f0bf15b9584fe49bcf1475fc8d38e9",
            "109144a7de6b411eb917733384f24de9"
          ]
        },
        "id": "uL5UIU_Tlxnz",
        "outputId": "b46c4d18-f41a-418f-9023-6b0963a855c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
            "INFO: GPU available: False, used: False\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: False, used: False\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO: Running in `fast_dev_run` mode: will run the requested loop using 1 batch(es). Logging and checkpointing is suppressed.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Running in `fast_dev_run` mode: will run the requested loop using 1 batch(es). Logging and checkpointing is suppressed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset length: 478\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: \n",
            "  | Name    | Type     | Params | Mode \n",
            "---------------------------------------------\n",
            "0 | net     | EmbroNet | 722 K  | train\n",
            "1 | loss_fn | MSELoss  | 0      | train\n",
            "---------------------------------------------\n",
            "722 K     Trainable params\n",
            "0         Non-trainable params\n",
            "722 K     Total params\n",
            "2.889     Total estimated model params size (MB)\n",
            "13        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name    | Type     | Params | Mode \n",
            "---------------------------------------------\n",
            "0 | net     | EmbroNet | 722 K  | train\n",
            "1 | loss_fn | MSELoss  | 0      | train\n",
            "---------------------------------------------\n",
            "722 K     Trainable params\n",
            "0         Non-trainable params\n",
            "722 K     Total params\n",
            "2.889     Total estimated model params size (MB)\n",
            "13        Modules in train mode\n",
            "0         Modules in eval mode\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "230177b74344490b8de7774a9bfc6aae"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: `Trainer.fit` stopped: `max_steps=1` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_steps=1` reached.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import lightning as L\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import Compose, ToTensor, Resize\n",
        "from dataset import EmbroDataset\n",
        "from model   import EmbroNet\n",
        "\n",
        "# ---------- 1. custom collate_fn ---------------------------------\n",
        "def pad_collate(batch):\n",
        "    \"\"\"\n",
        "    batch = list of (img_tensor, seq_tensor) pairs\n",
        "    Returns:\n",
        "        imgs   : B√ó3√ó128√ó128\n",
        "        tgt    : B√óLmax√ó3  (padded with 0s)\n",
        "        lens   : list[int] (original sequence lengths)\n",
        "    \"\"\"\n",
        "    imgs, seqs = zip(*batch)\n",
        "    imgs = torch.stack(imgs)                   # all same size\n",
        "\n",
        "    lens    = [s.size(0) for s in seqs]\n",
        "    Lmax    = max(lens)\n",
        "    padded  = torch.zeros(len(seqs), Lmax, 3)  # default zeros = padding\n",
        "    for i, s in enumerate(seqs):\n",
        "        padded[i, : lens[i], :] = s\n",
        "    return imgs, padded, torch.tensor(lens)\n",
        "\n",
        "# ---------- 2. LightningModule -----------------------------------\n",
        "class LitModule(L.LightningModule):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = EmbroNet()\n",
        "        self.loss_fn = torch.nn.MSELoss(reduction=\"mean\")\n",
        "\n",
        "    def forward(self, img, prev_cmds):\n",
        "        return self.net(img, prev_cmds)\n",
        "\n",
        "    def training_step(self, batch, _):\n",
        "        img, tgt, lens = batch                 # tgt: B√óLmax√ó3\n",
        "        pred = self(img, tgt[:, :-1])\n",
        "\n",
        "        # compute loss mask-aware\n",
        "        loss = 0.0\n",
        "        for i, L in enumerate(lens):\n",
        "            loss += self.loss_fn(pred[i, : L-1], tgt[i, 1 : L])  # valid region\n",
        "        loss = loss / len(lens)\n",
        "        self.log(\"train_loss\", loss)\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.AdamW(self.parameters(), 1e-3)\n",
        "\n",
        "# ---------- 3. dataset & dataloader ------------------------------\n",
        "tfms = Compose([Resize((128,128)), ToTensor()])\n",
        "ds   = EmbroDataset(IMG_DIR, DST_DIR, tfms)\n",
        "print(\"Dataset length:\", len(ds))          # should be > 0\n",
        "\n",
        "dl   = DataLoader(ds,\n",
        "                  batch_size=8,\n",
        "                  shuffle=True,\n",
        "                  num_workers=0,            # change later if you like\n",
        "                  collate_fn=pad_collate)   # ‚Üê custom collate!\n",
        "\n",
        "# ---------- 4. train ---------------------------------------------\n",
        "trainer = L.Trainer(fast_dev_run=True)\n",
        "#trainer = L.Trainer(max_epochs=10,\n",
        "                    #precision=\"16-mixed\",\n",
        "                    #accelerator=\"auto\")\n",
        "trainer.fit(LitModule(), dl)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob, pprint, os\n",
        "\n",
        "ckpts = glob.glob(\"/content/**/*epoch*=*.ckpt\", recursive=True)\n",
        "if ckpts:\n",
        "    pprint.pp(ckpts)\n",
        "else:\n",
        "    print(\"No checkpoints found ‚Äì you may need to save one first.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JeweUszAh5ov",
        "outputId": "adb15cba-1eb5-404f-849c-333aefa9b987"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No checkpoints found ‚Äì you may need to save one first.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# after your training run finishes\n",
        "trainer.save_checkpoint(\"/content/drive/MyDrive/EmbroideryTests/embronet_latest.ckpt\")\n"
      ],
      "metadata": {
        "id": "elEXvBfIi7-z"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (A) List any checkpoints Lightning has already saved\n",
        "import glob, pprint\n",
        "ckpts = glob.glob(\"/content/**/checkpoints/*.ckpt\", recursive=True)\n",
        "ckpts += glob.glob(\"/content/drive/**/checkpoints/*.ckpt\", recursive=True)\n",
        "pprint.pp(ckpts)\n",
        "\n",
        "# If the list prints something, copy one path:\n",
        "# CKPT_PATH = \"/content/lightning_logs/version_3/checkpoints/epoch=4-step=99.ckpt\"\n",
        "\n",
        "# (B) If the list is empty, save a quick checkpoint now (after training):\n",
        "trainer.save_checkpoint(\"/content/drive/MyDrive/EmbroideryTests/embronet.ckpt\")\n",
        "CKPT_PATH = \"/content/drive/MyDrive/EmbroideryTests/embronet.ckpt\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZd3T3lKqMga",
        "outputId": "eb18b95f-7383-41eb-fd4d-a3c4a407c303"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(\"checkpoint exists?\", os.path.exists(CKPT_PATH))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "165c0pq3ZEPy",
        "outputId": "e17845fc-352d-4d2d-a0eb-61cffb50a8a7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "checkpoint exists? True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#### ONE THAT WILL ACTUALLY WORK\n",
        "# ================================================================\n",
        "#  1‚ÄëCELL  PNG  ‚ûú  EmbroNet  ‚ûú  DST\n",
        "#  (just edit the three paths + SCALE, then press ‚ñ∂)\n",
        "# ================================================================\n",
        "CKPT_PATH = \"/content/drive/MyDrive/EmbroideryTests/embronet.ckpt\"  # <‚Äî your .ckpt\n",
        "PNG_PATH  = \"/content/drive/MyDrive/Embroidery Files/pngstart/MLPP_LOGO.PNG\"                 # <‚Äî input PNG\n",
        "OUT_PATH  = \"/content/drive/MyDrive/Embroidery Files/dststop/test_logo.dst\"         # <‚Äî output DST\n",
        "SCALE     = 7.0          # multiply Œîx,Œîy by this (set 1.0 if you trained with normalised targets)\n",
        "\n",
        "# --------------------------- code starts ---------------------------\n",
        "import torch, numpy as np\n",
        "from PIL import Image\n",
        "from torchvision.transforms import Compose, Resize, ToTensor\n",
        "from pyembroidery import EmbPattern, write\n",
        "from model import EmbroNet                                # <-- comes from model.py\n",
        "\n",
        "# --- load network -----------------------------------------------\n",
        "raw_state = torch.load(CKPT_PATH, map_location=\"cpu\")\n",
        "state     = raw_state[\"state_dict\"] if \"state_dict\" in raw_state else raw_state\n",
        "state     = {k.replace(\"net.\", \"\"): v for k, v in state.items()}   # strip \"net.\" prefix\n",
        "net = EmbroNet().eval()\n",
        "net.load_state_dict(state, strict=False)\n",
        "print(\"‚úì checkpoint loaded\")\n",
        "\n",
        "# --- preprocess PNG ----------------------------------------------\n",
        "tfms = Compose([Resize((128,128)), ToTensor()])\n",
        "img  = tfms(Image.open(PNG_PATH).convert(\"RGB\")).unsqueeze(0)   # 1√ó3√ó128√ó128\n",
        "\n",
        "# --- autoregressive inference ------------------------------------\n",
        "MAX_LEN = 4096\n",
        "with torch.no_grad():\n",
        "    seq = torch.zeros(1, 1, 3)      # start token (Œîx=Œîy=flag=0)\n",
        "    for _ in range(MAX_LEN):\n",
        "        pred = net(img, seq)        # B√óL√ó3\n",
        "        seq  = torch.cat([seq, pred[:, -1:, :]], dim=1)\n",
        "pred_seq = seq.squeeze(0)[1:]       # drop start token  (L√ó3)\n",
        "\n",
        "# --- rescale if needed -------------------------------------------\n",
        "pred_seq[:, :2] *= SCALE            # comment out if SCALE=1\n",
        "\n",
        "# --- build EmbPattern & save DST ---------------------------------\n",
        "pat = EmbPattern()\n",
        "x = y = 0.0\n",
        "for dx, dy, _ in pred_seq.numpy():\n",
        "    x += dx;  y += dy\n",
        "    pat.stitch(float(x), float(y))  # simple stitch; ignore flag for now\n",
        "pat.end()\n",
        "\n",
        "write(pat, OUT_PATH)\n",
        "print(\"‚úì saved\", OUT_PATH)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlXYQS4doEgT",
        "outputId": "3ce8682d-737d-48f4-b6d1-1ba7ea4ea46d"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úì checkpoint loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZTVlEDlYg75Y"
      },
      "outputs": [],
      "source": [
        "img, tgt = next(iter(dl))\n",
        "net = trainer.model.net.to(img.device)\n",
        "with torch.no_grad():\n",
        "    pred = net(img, tgt[:, :-1])\n",
        "print(\"GT  :\", tgt[0, :5])\n",
        "print(\"Pred:\", pred[0, :5])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNrlG2Ml9oubKK6KfPSD2Pl",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "230177b74344490b8de7774a9bfc6aae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fac27bea99c44f7cad19c2c15a16c82f",
              "IPY_MODEL_b9b93abe1b6d4c739f9886f6bcbb19d6",
              "IPY_MODEL_91162a4d61b6446c85cb1721f2e665dc"
            ],
            "layout": "IPY_MODEL_b9c7663ae33e412dba808faa9242fa46"
          }
        },
        "fac27bea99c44f7cad19c2c15a16c82f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58bdc58cf04545888d6d86ed03544b91",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_353f24df063c41b3ac06e0c270788933",
            "value": "Epoch‚Äá0:‚Äá100%"
          }
        },
        "b9b93abe1b6d4c739f9886f6bcbb19d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82355f83fbba453e8da018a7703ef0c2",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c4e8fde829b44ad1b3b78ad6291af1c9",
            "value": 1
          }
        },
        "91162a4d61b6446c85cb1721f2e665dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38f0bf15b9584fe49bcf1475fc8d38e9",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_109144a7de6b411eb917733384f24de9",
            "value": "‚Äá1/1‚Äá[00:18&lt;00:00,‚Äá‚Äá0.05it/s]"
          }
        },
        "b9c7663ae33e412dba808faa9242fa46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "58bdc58cf04545888d6d86ed03544b91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "353f24df063c41b3ac06e0c270788933": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "82355f83fbba453e8da018a7703ef0c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4e8fde829b44ad1b3b78ad6291af1c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "38f0bf15b9584fe49bcf1475fc8d38e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "109144a7de6b411eb917733384f24de9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}